---
title: 【CS336】BPE分词器训练
date: 2025-08-25 00:00:00 +/-TTTT
# categories: [TOP_CATEGORIE, SUB_CATEGORIE]
tags: [大模型, CS336]     # TAG names should always be lowercase
author: lyh
---

开个新坑～好几年没刷公开课了！

# 实现总结

- 环境：macbook m3 air 24G 512G
- TinystoriesV2-GPT4-train数据集：预分词约46秒，merge约5秒
- owt_train数据集：预分词约300秒，merge约1100秒

训练可以分为解耦的两大块，预分词、merge

# 预分词

使用讲义提供的正则表达式即可。

主要优化点就是多进程，这里我电脑只有8核所以就开个6进程，大家的CPU强的话进程数多多易善。

owt_train数据集的预分词需要做一下内存控制，在官方提供的`pretokenization_example.py`中做少许修改就可以实现。

由于预分词阶段没啥优化空间，我做了预分词结果缓存来跳过这个步骤，用python的pickle库。

预分词的结果我定义为`list[tuple[TokenList, Num]]`类型，all_token_list
即一个`[a,p,p,l,e]`这样的TokenList到其`出现次数`的映射，
这也是接下来的merge步骤的主数据结构。

# merge

## 初步实现

首先，我实现了一版能通过正确性测试的naive版本：
- 每次扫描all_token_list中所有的tuple，通过计算得到Connection关系，存入统计表`dict[Connection, Num]`
- 然后遍历统计表，得到Num最大的Connection，将其记录到merge_rules列表，这个合并结果记录到词汇表
- 使用刚生成的这条merge_rule，更新all_token_list
- 不断循环这个过程，直到词汇表达到上限

这里我遇到了一个正确性问题。在更新all_token_list的时候，起初我通过词表对每个TokenList做贪婪最长匹配，
这样得到的结果会和标准答案有微小的差别（第一个测试的第21次合并开始才会有差别）。正确的做法是严格按照merge_rule和“合并”的语义来操作。

这个bug是claude code写出来的，头疼了一晚上，第二天是gpt5 thinking查出来的。有了这个教训，这个课程我不会再让ai在关键路径上写任何代码......

## Connection统计缓存

有了正确实现之后，要做的优化是，对Connection关系进行缓存，不要每次全量扫all_token_list，毕竟每次合并之后能影响的词只占极少数。

这里我首先用了`dict[Connection, tuple[Num, set[Index]]`这样的结构来做缓存，即`Connection关系`->`(出现次数, 哪些TokenList有贡献)`

这个数据结构使得，每轮更新all_token_list的时候只需要处理对上一轮的merge_rule有贡献的那些TokenList，大大减少了计算量。

现在，基本就能1.5秒之内通过性能测试了，TinystoriesV2-GPT4-train数据集也能有不错的结果，
但owt_train依然会非常慢。主要原因在于，每次找到频率最高的Connection依然需要遍历整个缓存结构，
对本课程的数据集来说，缓存结构中会有10w量级的Connection存在。

## 缓存结构优化：有序计数桶

这样一来，就需要进一步优化这个缓存结构。为了能快速找到频率最高的Connection，容易想到可以使用堆。
但这里有个问题，这个缓存结构是需要不断对已存在的元素进行更新的。
堆确实能通过惰性删除等方式来实现更新，不过考虑到这种更新可能堆的尺寸过度膨胀，
我选择了另一个方案，有序计数桶。

数据结构为一个无序map和一个有序map，分别维护Connection->数量，和数量->Connection：
```python
class BucketMaxSD:
    def __init__(self):
        self.counts: dict[Connection, Num] = {}
        self.buckets = SortedDict() # Num->Set(Connection)
```

分析一下时间复杂度：
- 找到最大的元素：O(1)，由SortedDict保证
- 更新Connection Num关系：更新counts字典为O(1)，更新SortedDict至多需要做一次删除和一次插入，依然为O(log n)

顺便提一句，SortedDict来自第三方库sortedcontainer，其实现原理是一个“分块有序列表”，即list_of_list，
而不是常见的红黑树。它通过控制每个子list的长度和两次二分查找来实现写入操作的O(log n)摊还，和最大最小值的O(1)。

这个结构在owt_train实测中要好于堆，堆的性能可以参考这位同学：https://zhuanlan.zhihu.com/p/1920487178846344415

不过工业训练bpe分词器的过程，往往用的还是堆，参见：https://aclanthology.org/2023.findings-acl.38.pdf?utm_source=chatgpt.com
工业bpe的堆同样采用惰性实效的方式进行修改，据说会采用定期重建堆或者只维护top-k候选的方式控制堆的尺寸和内存占用，可能充分优化之后的堆具有更高的性能。
另外，工业上很多时候会采用并行merge，训练结果和本课程的单线程merge会有所区别，也有用Unigram这种不同于bpe的算法，有兴趣的同学可以进一步探索。

## 其它优化？

我和gpt5做了一些讨论，它给出了一些用双向链表来组织计数桶的方案，
但是通过实际数据来看，目前的数据结构在Num较大的尾端是相当稀疏的，
元素修改会经常性导致桶的新建和删除，导致双向链表并不适用。

那么继续使用有序计数桶，抽样表明merge过程90%的时间都消耗在数据结构的修改上，具体来说删除被merge_rule影响的Connection占据30%时间，新形成的Connection占据70%时间。

这里我观察到，在训练的前期，产生每条merge_rule需要数分钟时间，这个时间会越来越低。
我想这是因为前期Connection涉及到的贡献者会非常多，例如`t``h`组合，显然会有海量的词对这个组合产生贡献，而后期的组合的贡献者会越来越少。
这会不会有所启发呢？

总体来说，我对课程这个部分已经做得比较满意了，哈哈。

